{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/phoekoby/cnn-for-stegoanalysis?scriptVersionId=127501965\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip3 install torch torchvision","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-27T20:21:21.373013Z","iopub.execute_input":"2023-04-27T20:21:21.373716Z","iopub.status.idle":"2023-04-27T20:21:51.561595Z","shell.execute_reply.started":"2023-04-27T20:21:21.373679Z","shell.execute_reply":"2023-04-27T20:21:51.560331Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.13.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.14.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.4.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (9.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.21.6)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision) (2.28.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (1.26.14)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from collections import namedtuple\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport torch\nimport os\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport imageio as io\nimport pandas as pd\n\nimport torchvision.datasets as dset\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision.io import read_image\n\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2023-04-27T20:21:51.564456Z","iopub.execute_input":"2023-04-27T20:21:51.564878Z","iopub.status.idle":"2023-04-27T20:21:51.574577Z","shell.execute_reply.started":"2023-04-27T20:21:51.564825Z","shell.execute_reply":"2023-04-27T20:21:51.573571Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\")\n\ndef gaussian(x):\n  return torch.exp(-((x - torch.mean(x)) ** 2) / (torch.std(x)) ** 2) \n\nclass ConvBn(nn.Module):\n    \n    def __init__(self, in_channels: int, out_channels: int) -> None:\n        super().__init__()\n        self.conv = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=3,\n            stride=1,\n            padding=1,\n            bias=False,\n        )\n        self.batch_norm = nn.BatchNorm2d(out_channels)\n\n    def forward(self, inp):\n        return self.batch_norm(self.conv(inp))\n\n\nclass Type1(nn.Module):\n\n    def __init__(self, in_channels: int, out_channels: int) -> None:\n        super().__init__()\n        self.convbn = ConvBn(in_channels, out_channels)\n        self.relu = nn.ReLU()\n\n    def forward(self, inp):\n        return self.relu(self.convbn(inp))\n\n\nclass Type2(nn.Module):\n\n    def __init__(self, in_channels: int, out_channels: int) -> None:\n        super().__init__()\n        self.type1 = Type1(in_channels, out_channels)\n        self.convbn = ConvBn(in_channels, out_channels)\n\n    def forward(self, inp):\n        return inp + self.convbn(self.type1(inp))\n\n\nclass Type3(nn.Module):\n\n    def __init__(self, in_channels: int, out_channels: int) -> None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=1,\n            stride=2,\n            padding=0,\n            bias=False,\n        )\n        self.batch_norm = nn.BatchNorm2d(out_channels)\n        self.type1 = Type1(in_channels, out_channels)\n        self.convbn = ConvBn(out_channels, out_channels)\n        self.pool = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n\n    def forward(self, inp):\n        out = self.batch_norm(self.conv1(inp))\n        out1 = self.pool(self.convbn(self.type1(inp)))\n        return out + out1\n\n\nclass Type4(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int) -> None:\n        super().__init__()\n        self.type1 = Type1(in_channels, out_channels)\n        self.convbn = ConvBn(out_channels, out_channels)\n        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n\n    def forward(self, inp):\n        return self.gap(self.convbn(self.type1(inp)))\n\nclass Srnet(nn.Module):\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.type1s = nn.Sequential(Type1(1, 32), Type1(32, 8))\n        self.type2s = nn.Sequential(\n            Type2(8, 8),\n            Type2(8, 8),\n            Type2(8, 8),\n            Type2(8, 8),\n            Type2(8, 8),\n        )\n        self.type3s = nn.Sequential(\n            Type3(8, 8),\n            Type3(8, 32),\n            Type3(32, 64),\n            Type3(64, 128),\n        )\n        self.type4 = Type4(128, 256)\n        self.dense = nn.Linear(256, 2)\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, inp):\n        out = self.type1s(inp)\n        out = self.type2s(out)\n        out = self.type3s(out)\n        out = self.type4(out)\n        out = out.view(out.size(0), -1)\n        out = self.dense(out)\n        return self.softmax(out)\n\nclass Yenet(nn.Module):\n    def __init__(self):\n        super(Yenet, self).__init__()\n\n        self.tlu = nn.Hardtanh(min_val=-3.0, max_val=3.0)\n\n        self.conv2 = nn.Conv2d(30, 30, kernel_size=3, stride=1, padding=0)\n\n        self.conv3 = nn.Conv2d(30, 30, kernel_size=3, stride=1, padding=0)\n\n        self.conv4 = nn.Conv2d(30, 30, kernel_size=3, stride=1, padding=0)\n\n        self.conv5 = nn.Conv2d(30, 32, kernel_size=5, stride=1, padding=0)\n\n        self.conv6 = nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=0)\n\n        self.conv7 = nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=0)\n\n        self.conv8 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=0)\n\n        self.conv9 = nn.Conv2d(16, 16, kernel_size=3, stride=3, padding=0)\n\n        self.fc = nn.Linear(16 * 3 * 3, 2)\n        \n        self.sf = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        out = self.tlu(F.conv2d(x, srm_filters))\n        out = F.relu(self.conv2(out))\n        out = F.relu(self.conv3(out))\n        out = F.relu(self.conv4(out))\n        out = F.avg_pool2d(out, kernel_size=3, stride=2, padding=1)\n        out = F.relu(self.conv5(out))\n        out = F.avg_pool2d(out, kernel_size=3, stride=2, padding=0)\n        out = F.relu(self.conv6(out))\n        out = F.avg_pool2d(out, kernel_size=3, stride=2, padding=0)\n        out = F.relu(self.conv7(out))\n        out = F.avg_pool2d(out, kernel_size=3, stride=2, padding=0)\n        out = F.relu(self.conv8(out))\n        out = F.relu(self.conv9(out))\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        out = self.sf(out)\n        return out\n\nclass SteganalysisCNN(nn.Module):\n    def __init__(self):\n        super(SteganalysisCNN, self).__init__()\n        # self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n        # self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        # self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n        # self.fc1 = nn.Linear(64 * 8 * 8, 256)\n        # self.fc2 = nn.Linear(256, 2)\n\n\n        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(32)\n        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n        self.dr1 = nn.Dropout2d(p=0.1)\n        self.bn3 = nn.BatchNorm2d(32)\n        self.conv4 = nn.Conv2d(32, 16, 3, padding=1)\n        self.bn4 = nn.BatchNorm2d(16)\n        self.conv5 = nn.Conv2d(16, 8, 3, padding=1)\n        self.bn5 = nn.BatchNorm2d(8)\n        self.conv6 = nn.Conv2d(8, 16, 3, padding=1)\n        self.bn6 = nn.BatchNorm2d(16)\n        self.conv7 = nn.Conv2d(16, 16, 3, padding=1)\n        self.bn7 = nn.BatchNorm2d(16)\n        self.conv8 = nn.Conv2d(8, 16, 3, padding=1)\n        self.dr2 = nn.Dropout2d(p=0.5)\n        self.bn8 = nn.BatchNorm2d(16)\n        self.fc1 = nn.Linear(16 * 16 * 16, 128)\n        self.dr3 = nn.Dropout(p=0.3)\n        self.fc2 = nn.Linear(128, 32)\n        self.dr4 = nn.Dropout(p=0.3)\n        self.fc3 = nn.Linear(32, 2)\n        self.sfm = nn.Softmax(dim = 1)\n\n    def forward(self, x):\n        # x = F.relu(self.conv1(x))\n        # x = F.max_pool2d(x, 4)\n        # x = F.relu(self.conv2(x))\n        # x = F.max_pool2d(x, 4)\n        # x = F.relu(self.conv3(x))\n        # x = F.max_pool2d(x, 4)\n        # x = x.view(-1, 64 * 8 * 8)\n        # x = F.relu(self.fc1(x))\n        # x = self.fc2(x)\n\n\n        # x = F.relu(self.bn1(self.conv1(x)))\n        x = gaussian(self.bn1(self.conv1(x)))\n        x = F.max_pool2d(x, 2)\n        # x = F.relu(self.bn2(self.conv2(x)))\n        x = gaussian(self.bn2(self.conv2(x)))\n        x = F.max_pool2d(x, 2)\n        # x = F.relu(self.bn3(self.conv3(x)))\n        x = gaussian(self.bn3(self.conv3(x)))\n        # x = self.dr1(x)\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.bn5(self.conv5(x)))\n        x = F.max_pool2d(x, 2)\n        # x = F.relu(self.bn6(self.conv6(x)))\n        # x = F.max_pool2d(x, 2)\n        # x = F.relu(self.bn7(self.conv7(x)))\n        # x = F.max_pool2d(x, 2)\n        x = F.relu(self.bn8(self.conv8(x)))\n        # x = self.dr2(x)\n        x = x.view(-1, 16 * 16 * 16)\n        x = F.relu(self.fc1(x))\n        # x = self.dr3(x)\n        x = self.fc2(x)\n        x = self.sfm(x)\n        return x\n\nclass CustomDataset:\n    def __init__(self, img_dir,amount, transform=None, target_transform=None):\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n        self.amount = amount\n\n    def __len__(self):\n        return self.amount\n\n    def __getitem__(self, idx):\n        image = None\n        num = int(idx / 2) + 1\n        label = idx % 2\n        if label == 0:\n            image = PIL.Image.open(self.img_dir + \"cover/\" +  str(num) + \".pgm\")\n        else:\n            image = PIL.Image.open(self.img_dir + \"stego/\" +  str(num) + \".pgm\")\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        idx += 1\n        return (image, label)\n\ndata_train = CustomDataset('/kaggle/input/boss-base/train_set_databoss/', 14000, transform=transforms.Compose([\n#                            transforms.RandomRotation(50, interpolation=PIL.Image.BILINEAR),\n                           transforms.ToTensor(),\n#                            transforms.Normalize(\n#                                 mean=[0.485, 0.456, 0.406],\n#                                 std=[0.229, 0.224, 0.225],\n#                             )\n]))\ndata_test = CustomDataset('/kaggle/input/boss-base/test_set_databoss/',6000, transform=transforms.Compose([\n#                             transforms.RandomRotation(50, interpolation=PIL.Image.BILINEAR),\n                           transforms.ToTensor(),\n#                            transforms.Normalize(\n#                                 mean=[0.485, 0.456, 0.406],\n#                                 std=[0.229, 0.224, 0.225],                       \n#                        )\n]))\n\nbatch_size = 32\n\ndata_size = 7000\n\nvalidation_split = .2\n\nnum_epochs = 100\n\nsplit = int(np.floor(validation_split * data_size))\nindices = list(range(data_size))\n\nnp.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]\n\ntrain_sampler = SubsetRandomSampler(train_indices)\nval_sampler = SubsetRandomSampler(val_indices)\n\n\n\n# Load the dataset using DataLoader\ntrain_loader = DataLoader(data_train, batch_size=batch_size, sampler=train_sampler)\nval_loader = DataLoader(data_train, batch_size=batch_size, sampler=val_sampler)\n\n\n\n# nn_model = SteganalysisCNN()\n\nnn_model = Srnet()\n\nnn_model.type(torch.cuda.FloatTensor)\nnn_model.to(device)\n\ncriterion = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n\noptimizer = torch.optim.Adamax(\n        nn_model.parameters(),\n        lr=0.01,\n        betas=(0.9, 0.999),\n#         eps=1e-8,\n        # weight_decay=1e-6,\n    )\n# optimizer = optim.Adam(nn_model.parameters(), lr=0.001, betas=(0.95, 0.999), weight_decay=1e-5, eps=1e-8)\n\ndef train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):\n    loss_history = []\n    train_history = []\n    val_history = []\n    val_losses = []\n    for epoch in range(num_epochs):\n        model.train()\n        loss_accum = 0\n        correct_samples = 0\n        total_samples = 0\n        running_loss = 0.0\n        for i, data in enumerate(train_loader):\n            inputs, labels = data\n            x_gpu = inputs.to(device)\n            y_gpu = labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(x_gpu)\n            loss = criterion(outputs, y_gpu)\n\n            loss.backward()\n            optimizer.step()\n\n            _, indices = torch.max(outputs, 1)\n            correct_samples += torch.sum(indices == y_gpu)\n            total_samples += labels.shape[0]\n            \n            loss_accum += loss\n\n        ave_loss = loss_accum / i\n        train_accuracy = float(correct_samples) / total_samples\n        val_accuracy, val_loss = compute_accuracy(model, val_loader)\n        \n        loss_history.append(float(ave_loss))\n        train_history.append(train_accuracy)\n        val_history.append(val_accuracy)\n        val_losses.append(val_loss)\n        \n        print(\"Epoch: %d, Average loss: %f, Validation loss: %f, Train accuracy: %f, Val accuracy: %f\" % (epoch, ave_loss, val_loss, train_accuracy, val_accuracy))\n        \n    return loss_history, train_history, val_history, val_losses\n\ndef compute_accuracy(model, loader):\n    model.eval()\n    total = 0\n    correct = 0\n    losses = []\n    with torch.no_grad():\n        for i_step, (x, y) in enumerate(loader):\n            x_gpu = x.to(device)\n            y_gpu = y.to(device)\n            predictions = model(x_gpu)\n            loss = criterion(predictions, y_gpu)\n            losses.append(loss.item())\n            _, predicted = torch.max(predictions.data, 1)\n            total += y_gpu.size(0)\n            correct += (predicted == y_gpu).sum().item()\n    return correct/total, sum(losses)/len(losses)\n\ndef Plt_hist(loss_history, train_history, val_history, val_losses):\n     plt.plot(train_history)\n     plt.plot(val_history)\n     plt.title('model accuracy')\n     plt.xlabel('epoch')\n     plt.ylabel('accuracy')\n     plt.legend(['train','validation'], loc='upper left')\n     plt.grid()\n     plt.show()\n     plt.plot(loss_history)\n     plt.plot(val_losses)\n     plt.title('model loss')\n     plt.xlabel('epoch')\n     plt.ylabel('loss')\n     plt.legend(['model loss', 'val loss'], loc='upper left')\n     plt.grid()\n     plt.show()\n\nloss_history, train_history, val_history, val_losses = train_model(nn_model, train_loader, val_loader, criterion, optimizer, num_epochs)\n\nPlt_hist(loss_history, train_history, val_history, val_losses)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T20:21:51.578211Z","iopub.execute_input":"2023-04-27T20:21:51.578605Z","iopub.status.idle":"2023-04-27T22:27:46.78151Z","shell.execute_reply.started":"2023-04-27T20:21:51.578559Z","shell.execute_reply":"2023-04-27T22:27:46.779399Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch: 0, Average loss: 0.724245, Validation loss: 0.701530, Train accuracy: 0.513929, Val accuracy: 0.502857\nEpoch: 1, Average loss: 0.700970, Validation loss: 0.694658, Train accuracy: 0.501607, Val accuracy: 0.521429\nEpoch: 2, Average loss: 0.699415, Validation loss: 0.695069, Train accuracy: 0.507500, Val accuracy: 0.507857\nEpoch: 3, Average loss: 0.697730, Validation loss: 0.693055, Train accuracy: 0.497500, Val accuracy: 0.510000\nEpoch: 4, Average loss: 0.697439, Validation loss: 0.693239, Train accuracy: 0.494464, Val accuracy: 0.502857\nEpoch: 5, Average loss: 0.697943, Validation loss: 0.693336, Train accuracy: 0.501786, Val accuracy: 0.487857\nEpoch: 6, Average loss: 0.697958, Validation loss: 0.693401, Train accuracy: 0.503750, Val accuracy: 0.492143\nEpoch: 7, Average loss: 0.697954, Validation loss: 0.693418, Train accuracy: 0.496786, Val accuracy: 0.492143\nEpoch: 8, Average loss: 0.697318, Validation loss: 0.693152, Train accuracy: 0.503393, Val accuracy: 0.507857\nEpoch: 9, Average loss: 0.697443, Validation loss: 0.693422, Train accuracy: 0.496964, Val accuracy: 0.492143\nEpoch: 10, Average loss: 0.698024, Validation loss: 0.693430, Train accuracy: 0.494643, Val accuracy: 0.476429\nEpoch: 11, Average loss: 0.697498, Validation loss: 0.693366, Train accuracy: 0.501786, Val accuracy: 0.492143\nEpoch: 12, Average loss: 0.698226, Validation loss: 0.693801, Train accuracy: 0.493571, Val accuracy: 0.477857\nEpoch: 13, Average loss: 0.700515, Validation loss: 0.694219, Train accuracy: 0.498571, Val accuracy: 0.507857\nEpoch: 14, Average loss: 0.699660, Validation loss: 0.699216, Train accuracy: 0.498571, Val accuracy: 0.492143\nEpoch: 15, Average loss: 0.699674, Validation loss: 0.703400, Train accuracy: 0.501964, Val accuracy: 0.492143\nEpoch: 16, Average loss: 0.699166, Validation loss: 0.693420, Train accuracy: 0.504107, Val accuracy: 0.502143\nEpoch: 17, Average loss: 0.697878, Validation loss: 0.697544, Train accuracy: 0.502679, Val accuracy: 0.492143\nEpoch: 18, Average loss: 0.699327, Validation loss: 0.693728, Train accuracy: 0.491964, Val accuracy: 0.507857\nEpoch: 19, Average loss: 0.699549, Validation loss: 0.693635, Train accuracy: 0.493571, Val accuracy: 0.494286\nEpoch: 20, Average loss: 0.699085, Validation loss: 0.693786, Train accuracy: 0.495893, Val accuracy: 0.495000\nEpoch: 21, Average loss: 0.698199, Validation loss: 0.695534, Train accuracy: 0.513036, Val accuracy: 0.492143\nEpoch: 22, Average loss: 0.699468, Validation loss: 0.693024, Train accuracy: 0.485179, Val accuracy: 0.509286\nEpoch: 23, Average loss: 0.700156, Validation loss: 0.693924, Train accuracy: 0.491607, Val accuracy: 0.487857\nEpoch: 24, Average loss: 0.699961, Validation loss: 0.701533, Train accuracy: 0.493214, Val accuracy: 0.492143\nEpoch: 25, Average loss: 0.699256, Validation loss: 0.695029, Train accuracy: 0.504464, Val accuracy: 0.492143\nEpoch: 26, Average loss: 0.699088, Validation loss: 0.699085, Train accuracy: 0.503214, Val accuracy: 0.492143\nEpoch: 27, Average loss: 0.698859, Validation loss: 0.695890, Train accuracy: 0.508036, Val accuracy: 0.495000\nEpoch: 28, Average loss: 0.698547, Validation loss: 0.693802, Train accuracy: 0.488571, Val accuracy: 0.492143\nEpoch: 29, Average loss: 0.698368, Validation loss: 0.693196, Train accuracy: 0.495179, Val accuracy: 0.494286\nEpoch: 30, Average loss: 0.697531, Validation loss: 0.693532, Train accuracy: 0.482857, Val accuracy: 0.492143\nEpoch: 31, Average loss: 0.698166, Validation loss: 0.693860, Train accuracy: 0.498929, Val accuracy: 0.492143\nEpoch: 32, Average loss: 0.699066, Validation loss: 0.694176, Train accuracy: 0.487679, Val accuracy: 0.492143\nEpoch: 33, Average loss: 0.698215, Validation loss: 0.694018, Train accuracy: 0.496607, Val accuracy: 0.492143\nEpoch: 34, Average loss: 0.698279, Validation loss: 0.693595, Train accuracy: 0.506250, Val accuracy: 0.492143\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3187967556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    389\u001b[0m      \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0mPlt_hist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/3187967556.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, loss, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mx_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0my_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}